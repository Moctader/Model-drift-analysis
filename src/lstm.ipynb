{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import Any\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD CSV INTO DICT ARRAY\n",
    "def load_csv(file_name):\n",
    "    container = []\n",
    "    file_path = f'{file_name}'\n",
    "\n",
    "    with open(file_path, mode='r', newline='') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            container.append(row)\n",
    "\n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class create_model_suite:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "    \n",
    "        self.raw_data = pd.read_csv('finance_historical.csv')\n",
    "        #self.fifth_row = self.raw_data.iloc[4]   \n",
    "\n",
    "        # References to model layers\n",
    "        self.references = {\n",
    "            'lstm': LSTM,\n",
    "            'dense': Dense,\n",
    "        }\n",
    "\n",
    "    ########################################################################################################\n",
    "    ########################################################################################################\n",
    "\n",
    "\n",
    "    def train_model(self, model_name: str, model_params: dict) -> None:\n",
    "        try:\n",
    "            # Feature extraction: Reshaping 'close' prices to use as input\n",
    "            X = self.raw_data[['open', 'high', 'low', 'volume']]\n",
    "\n",
    "            # Define the target variable for classification (binary: 1 if next close > current close, else 0)\n",
    "            self.raw_data['target'] = (self.raw_data['close'].shift(-1) > self.raw_data['close']).astype(int)\n",
    "            y = self.raw_data['target'].values[:-1]  # Exclude the last row due to NaN from the shift\n",
    "            X = X[:-1]  # Align X with y\n",
    "\n",
    "            # Impute missing values in X using the median strategy\n",
    "            imputer = SimpleImputer(strategy='median')\n",
    "            X = imputer.fit_transform(X)\n",
    "\n",
    "            # Reshape X for LSTM input (samples, timesteps, features)\n",
    "            X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "            model_layers = []\n",
    "\n",
    "            # Iterate over the layers defined in model_params['layers']\n",
    "            for i, layer_params in enumerate(model_params['layers']):\n",
    "                layer_type = layer_params['type']  # 'lstm' or 'dense'\n",
    "                layer_class = self.references.get(layer_type)  # Lookup corresponding class (e.g., LSTM, Dense)\n",
    "\n",
    "                if layer_class is None:\n",
    "                    raise ValueError(f\"Layer type '{layer_type}' not found in references.\")\n",
    "\n",
    "                # For LSTM layers, we need to pass input_shape for the first layer\n",
    "                if i == 0 and 'input_shape' in layer_params:\n",
    "                    # First layer requires input_shape\n",
    "                    layer = layer_class(\n",
    "                        units=layer_params['units'],\n",
    "                        activation=layer_params['activation_func'],\n",
    "                        input_shape=layer_params['input_shape']\n",
    "                    )\n",
    "                else:\n",
    "                    # Subsequent layers don't require input_shape\n",
    "                    layer = layer_class(\n",
    "                        units=layer_params['units'],\n",
    "                        activation=layer_params['activation_func']\n",
    "                    )\n",
    "                \n",
    "                # Add layer to model\n",
    "                model_layers.append(layer)\n",
    "\n",
    "            # Initialize the Sequential model with dynamically built layers\n",
    "            self.model = Sequential(model_layers)\n",
    "\n",
    "            # Dynamically set optimizer, loss function, and metrics\n",
    "            optimizer = model_params.get('optimizer', Adam(learning_rate=0.001))  # Default to Adam optimizer\n",
    "            loss_function = model_params.get('loss', 'binary_crossentropy')       # Default to binary cross-entropy\n",
    "            metrics = model_params.get('metrics', ['accuracy'])                   # Default to accuracy metric\n",
    "\n",
    "            # Compile the model with dynamic parameters\n",
    "            self.model.compile(optimizer=optimizer, loss=loss_function, metrics=metrics)\n",
    "\n",
    "            # Train the model with dynamic epochs and batch size\n",
    "            self.model.fit(\n",
    "                X, y, \n",
    "                epochs=model_params.get('epochs', 50), \n",
    "                batch_size=model_params.get('batch_size', 32), \n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "            # Evaluate the model's performance\n",
    "            y_pred = (self.model.predict(X) > 0.5).astype(\"int32\")\n",
    "            accuracy = accuracy_score(y, y_pred)\n",
    "            print(f\"Model trained with accuracy: {accuracy}\")\n",
    "\n",
    "            # Save the model to the current directory\n",
    "            self.model.save(f'{model_name}.keras')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during model training: {e}\")\n",
    "            raise\n",
    "\n",
    "    ########################################################################################################\n",
    "    ########################################################################################################\n",
    "\n",
    "    def load_model(self, model_name: str) -> None:\n",
    "        if self.model is not None:\n",
    "            raise Exception('LOAD ERROR: A MODEL HAS ALREADY BEEN LOADED')\n",
    "        try:\n",
    "            self.model = tf.keras.models.load_model(f'{model_name}.keras')\n",
    "            print(f\"Model loaded from {model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            raise\n",
    "\n",
    "    ########################################################################################################\n",
    "    ########################################################################################################\n",
    "\n",
    "    def predict_outcome(self, row_index: int) -> Any:\n",
    "        if self.model is None:\n",
    "            raise Exception('PREDICT ERROR: LOAD A MODEL FIRST')\n",
    "        try:\n",
    "            # Select the features for the specified row (ensure these are the same features used for training)\n",
    "            input_data = self.raw_data.iloc[row_index:row_index+1][['open', 'high', 'low', 'volume']]\n",
    "    \n",
    "            # Reshape the input data for LSTM: (samples, timesteps, features)\n",
    "            X = input_data.values.reshape((1, 1, -1))  # 1 sample, 1 timestep, and features count\n",
    "    \n",
    "            # Make the prediction\n",
    "            prediction = self.model.predict(X)\n",
    "            return prediction\n",
    "        except Exception as e:\n",
    "            print(f\"Error during prediction: {e}\")\n",
    "            raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define valid model parameters with dynamic optimizer, loss, and metrics\n",
    "suite = create_model_suite()\n",
    "\n",
    "model_params = {\n",
    "    'epochs': 100,\n",
    "    'batch_size': 32,\n",
    "    'model_tag': 'v1',\n",
    "    'version': 1,\n",
    "    'optimizer': Adam(learning_rate=0.001),\n",
    "    'loss': 'binary_crossentropy',\n",
    "    'metrics': ['accuracy', 'mse'],\n",
    "    'layers': [\n",
    "        {\n",
    "            'type': 'lstm',\n",
    "            'units': 50,\n",
    "            'activation_func': 'relu',\n",
    "        },\n",
    "        {\n",
    "            'type': 'dense',\n",
    "            'units': 1,\n",
    "            'activation_func': 'sigmoid'\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Train the model using the dynamic model parameters\n",
    "suite.train_model('LSTM', model_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the same model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = create_model_suite()\n",
    "suite.load_model('LSTM')\n",
    "\n",
    "row_index=9\n",
    "prediction = suite.predict_outcome(row_index)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "class create_model_suite:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.raw_data = None\n",
    "        self.timesteps = 3  # Number of timesteps for LSTM (look-back period)\n",
    "        self.scaler = None\n",
    "        self.imputer = None\n",
    "\n",
    "        # References to model layers\n",
    "        self.references = {\n",
    "            'lstm': LSTM,\n",
    "            'dense': Dense,\n",
    "        }\n",
    "\n",
    "    def load_data(self, file_name: str) -> None:\n",
    "        \"\"\" Load data from a CSV file \"\"\"\n",
    "        try:\n",
    "            self.raw_data = pd.read_csv(file_name)\n",
    "            print(\"Data loaded successfully.\")\n",
    "            print(self.raw_data.head(5))\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load data: {e}\")\n",
    "\n",
    "    def train_model(self, model_params: dict) -> None:\n",
    "        \"\"\" Train an LSTM model with specified parameters \"\"\"\n",
    "        if self.raw_data is None or self.raw_data.empty:\n",
    "            print(\"No data available to train the model.\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Ensure timestamp is parsed correctly (if applicable)\n",
    "            if 'timestamp' in self.raw_data.columns:\n",
    "                self.raw_data['timestamp'] = pd.to_datetime(self.raw_data['timestamp'])\n",
    "\n",
    "            # Select the features and target\n",
    "            X = self.raw_data[['open', 'high', 'low', 'volume']]\n",
    "            y = self.raw_data['adjusted_close']\n",
    "\n",
    "            # Impute missing values in X\n",
    "            self.imputer = SimpleImputer(strategy='median')\n",
    "            X = self.imputer.fit_transform(X)\n",
    "\n",
    "            # Normalize features\n",
    "            self.scaler = StandardScaler()\n",
    "            X = self.scaler.fit_transform(X)\n",
    "            \n",
    "            # Prepare sequences for LSTM\n",
    "            X, y = self.create_sequences(X, y.values, self.timesteps)\n",
    "            \n",
    "            # Split data into training and testing sets\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "            # Initialize and configure the LSTM model\n",
    "            model_layers = []\n",
    "            for i, layer_params in enumerate(model_params['layers']):\n",
    "                layer_type = layer_params['type']\n",
    "                layer_class = self.references.get(layer_type)\n",
    "                \n",
    "                if layer_class is None:\n",
    "                    raise ValueError(f\"Layer type '{layer_type}' not found in references.\")\n",
    "\n",
    "                # Add LSTM layers with input_shape for the first layer\n",
    "                if i == 0:\n",
    "                    layer = layer_class(\n",
    "                        units=layer_params['units'],\n",
    "                        activation=layer_params['activation_func'],\n",
    "                        input_shape=layer_params['input_shape']\n",
    "                    )\n",
    "                else:\n",
    "                    # Subsequent layers don't require input_shape\n",
    "                    layer = layer_class(\n",
    "                        units=layer_params['units'],\n",
    "                        activation=layer_params['activation_func']\n",
    "                    )\n",
    "                model_layers.append(layer)\n",
    "\n",
    "            # Add Dense output layer for regression\n",
    "            model_layers.append(Dense(1, activation='linear'))  # Output layer for regression\n",
    "            \n",
    "            # Initialize the Sequential model with dynamically built layers\n",
    "            self.model = Sequential(model_layers)\n",
    "\n",
    "            # Dynamically set optimizer, loss function, and metrics\n",
    "            optimizer = model_params.get('optimizer', Adam(learning_rate=0.001))\n",
    "            loss_function = model_params.get('loss', 'mean_squared_error')\n",
    "            metrics = model_params.get('metrics', ['mae'])\n",
    "    \n",
    "            self.model.compile(optimizer=optimizer, loss=loss_function, metrics=metrics)\n",
    "            self.model.fit(\n",
    "                X_train, y_train, \n",
    "                epochs=model_params.get('epochs', 50), \n",
    "                batch_size=model_params.get('batch_size', 32), \n",
    "                verbose=1\n",
    "            )\n",
    "    \n",
    "            # Evaluate the model's performance\n",
    "            y_pred = self.model.predict(X_test)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            print(f\"Model trained with MSE: {mse}\")\n",
    "\n",
    "            # Save the model\n",
    "            model_filename = f'model_lstm_{model_params.get(\"model_tag\", \"v1\")}.keras'\n",
    "            self.model.save(model_filename)\n",
    "            print(f\"Model saved as {model_filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during model training: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "\n",
    "    def load_model(self, model_name: str) -> None:\n",
    "        if self.model is not None:\n",
    "            raise Exception('LOAD ERROR: A MODEL HAS ALREADY BEEN LOADED')\n",
    "        try:\n",
    "            self.model = tf.keras.models.load_model(f'{model_name}.keras')\n",
    "            print(f\"Model loaded from {model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            raise\n",
    "\n",
    "    def predict_outcome(self, input_data: dict) -> Any:\n",
    "        \"\"\" Predict the outcome based on input data \"\"\"\n",
    "        if self.model is None:\n",
    "            raise Exception('PREDICT ERROR: LOAD A MODEL FIRST')\n",
    "        \n",
    "        try:\n",
    "            # Convert input data to DataFrame for consistency\n",
    "            input_df = pd.DataFrame([input_data])\n",
    "            \n",
    "            # Impute missing values and normalize features\n",
    "            input_df = self.imputer.transform(input_df)\n",
    "            input_df = self.scaler.transform(input_df)\n",
    "            \n",
    "            # Ensure the input data has the correct number of features\n",
    "            if input_df.shape[1] != self.raw_data[['open', 'high', 'low', 'volume']].shape[1]:\n",
    "                raise ValueError(\"The number of features in the input data does not match the training data.\")\n",
    "    \n",
    "            # Prepare sequence for LSTM input\n",
    "            # Since we're predicting a single point, we need to simulate a sequence\n",
    "            if input_df.shape[0] < self.timesteps:\n",
    "                # Repeat the input data to simulate the sequence\n",
    "                repeated_input = np.tile(input_df, (self.timesteps, 1))\n",
    "            else:\n",
    "                # Slice the last `timesteps` data points if input_data contains a sufficient number of data points\n",
    "                repeated_input = input_df[-self.timesteps:]\n",
    "            \n",
    "            # Reshape to fit LSTM input\n",
    "            input_sequence = np.reshape(repeated_input, (1, self.timesteps, input_df.shape[1]))\n",
    "            \n",
    "            # Make the prediction\n",
    "            prediction = self.model.predict(input_sequence)\n",
    "            return prediction.flatten()[0]\n",
    "        except Exception as e:\n",
    "            print(f\"Error during prediction: {e}\")\n",
    "            raise\n",
    "\n",
    "    def create_sequences(self, data, target, timesteps):\n",
    "        \"\"\" Create sequences for LSTM input \"\"\"\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - timesteps):\n",
    "            X.append(data[i:i + timesteps])\n",
    "            y.append(target[i + timesteps])\n",
    "        return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Create an instance of the model suite\n",
    "suite = create_model_suite()\n",
    "\n",
    "# Load the data\n",
    "suite.load_data('finance_historical.csv')\n",
    "\n",
    "# Define model parameters\n",
    "model_params = {\n",
    "    'model_tag': 'v1',\n",
    "    'layers': [\n",
    "        {'type': 'lstm', 'units': 50, 'activation_func': 'tanh', 'input_shape': (10, 4)},\n",
    "        {'type': 'dense', 'units': 25, 'activation_func': 'relu'}\n",
    "    ],\n",
    "    'optimizer': 'adam',\n",
    "    'loss': 'mean_squared_error',\n",
    "    'metrics': ['accuracy'],\n",
    "    'epochs': 20,\n",
    "    'batch_size': 32\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "suite.train_model(model_params)\n",
    "\n",
    "# Load the model and make a prediction\n",
    "#suite.load_model({'model_tag': 'v1'})\n",
    "\n",
    "# Sample input data for prediction\n",
    "sample_input = {\n",
    "    'open': 7.5,\n",
    "    'high': 7.6,\n",
    "    'low': 7.4,\n",
    "    'volume': 600000000\n",
    "}\n",
    "\n",
    "# Make a prediction\n",
    "try:\n",
    "    prediction = suite.predict_outcome(sample_input)\n",
    "    print(f\"Predicted Adjusted Close Price: {prediction}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during prediction: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = create_model_suite()\n",
    "suite.load_model('model_lstm_v1')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
